"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —É–º–Ω–æ–≥–æ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è EPG –¥–∞–Ω–Ω—ã–º–∏.
–§–æ–∫—É—Å –Ω–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ –ø—Ä–æ—Å—Ç–æ—Ç–µ.
"""

from __future__ import annotations

import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Any, Dict, List, Optional

from .config import Config
from .iptv_api import fetch_epg as _original_fetch_epg

logger = logging.getLogger(__name__)


class SimpleEPGManager:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä EPG —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω—ã–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º."""
    
    def __init__(self, data_dir: str = "data"):
        self.data_dir = Path(data_dir)
        self.raw_epg_file = self.data_dir / "raw_epg.json"
        self.metadata_file = self.data_dir / "epg_smart_metadata.json"
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.default_past_days = 7
        self.default_future_days = 14
        self.cleanup_days = 30
    
    def should_update_epg(self) -> tuple[bool, str]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å EPG –¥–∞–Ω–Ω—ã–µ.
        
        Returns:
            (should_update, reason)
        """
        if not self.raw_epg_file.exists():
            return True, "–§–∞–π–ª EPG –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
        
        if not self.metadata_file.exists():
            return True, "–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç"
        
        try:
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            last_update_str = metadata.get('last_update')
            if not last_update_str:
                return True, "–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏"
            
            last_update = datetime.fromisoformat(last_update_str)
            hours_since_update = (datetime.now() - last_update).total_seconds() / 3600
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –µ—Å–ª–∏ –ø—Ä–æ—à–ª–æ –±–æ–ª—å—à–µ 6 —á–∞—Å–æ–≤
            if hours_since_update > 6:
                return True, f"–ü—Ä–æ—à–ª–æ {hours_since_update:.1f} —á–∞—Å–æ–≤ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è"
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–∞—Ç
            coverage = metadata.get('date_coverage', {})
            if not coverage:
                return True, "–ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–æ–∫—Ä—ã—Ç–∏–∏ –¥–∞—Ç"
            
            coverage_start = datetime.fromisoformat(coverage['start']).date()
            coverage_end = datetime.fromisoformat(coverage['end']).date()
            
            today = datetime.now().date()
            target_start = today - timedelta(days=self.default_past_days)
            target_end = today + timedelta(days=self.default_future_days)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω—ã –ª–∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
            if coverage_start > target_start:
                return True, f"–ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ —Å {target_start} (–µ—Å—Ç—å —Å {coverage_start})"
            
            if coverage_end < target_end:
                return True, f"–ù—É–∂–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–æ {target_end} (–µ—Å—Ç—å –¥–æ {coverage_end})"
            
            return False, "–î–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã"
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            return True, f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}"
    
    def get_optimal_request_params(self) -> Dict[str, str]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ EPG."""
        today = datetime.now().date()
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
        start_date = today - timedelta(days=self.default_past_days)
        end_date = today + timedelta(days=self.default_future_days)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ, –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å
        if self.metadata_file.exists():
            try:
                with open(self.metadata_file, 'r', encoding='utf-8') as f:
                    metadata = json.load(f)
                
                coverage = metadata.get('date_coverage', {})
                if coverage:
                    existing_start = datetime.fromisoformat(coverage['start']).date()
                    existing_end = datetime.fromisoformat(coverage['end']).date()
                    
                    # –†–∞—Å—à–∏—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Ç–æ–ª—å–∫–æ –≤ –Ω—É–∂–Ω—É—é —Å—Ç–æ—Ä–æ–Ω—É
                    if existing_start <= start_date and existing_end >= end_date:
                        # –î–∞–Ω–Ω—ã–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é –ø–æ–∫—Ä—ã–≤–∞—é—Ç –Ω—É–∂–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
                        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –º–∏–Ω–∏–º—É–º –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
                        start_date = today - timedelta(days=1)
                        end_date = today + timedelta(days=2)
                    elif existing_end >= today:
                        # –ï—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –±—É–¥—É—â–µ–µ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—Ä–æ—à–ª–æ–µ
                        end_date = min(end_date, existing_end)
                    elif existing_start <= today:
                        # –ï—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∞ –ø—Ä–æ—à–ª–æ–µ, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –±—É–¥—É—â–µ–µ
                        start_date = max(start_date, existing_start)
                        
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
        
        # –í—ã—á–∏—Å–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å–µ–≥–æ–¥–Ω—è—à–Ω–µ–≥–æ –¥–Ω—è
        days_from_today_start = (start_date - today).days
        days_total = (end_date - start_date).days + 1
        
        return {
            "epg_from": str(days_from_today_start),
            "epg_limit": str(days_total)
        }
    
    def merge_epg_data(self, existing_data: List[Dict], new_data: List[Dict]) -> List[Dict]:
        """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç EPG –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–Ω—è–º."""
        logger.info(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ EPG: {len(existing_data)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–Ω–µ–π + {len(new_data)} –Ω–æ–≤—ã—Ö")
        
        # –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ –ø–æ –¥–∞—Ç–µ
        existing_by_date = {}
        for day in existing_data:
            date_key = day.get('date', '')
            if date_key:
                existing_by_date[date_key] = day
        
        # –î–æ–±–∞–≤–ª—è–µ–º/–æ–±–Ω–æ–≤–ª—è–µ–º –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        updated_count = 0
        added_count = 0
        
        for new_day in new_data:
            date_key = new_day.get('date', '')
            if not date_key:
                continue
                
            if date_key in existing_by_date:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –¥–µ–Ω—å
                existing_by_date[date_key] = new_day
                updated_count += 1
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–π –¥–µ–Ω—å
                existing_by_date[date_key] = new_day
                added_count += 1
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –¥–∞–Ω–Ω—ã–µ
        cutoff_date = datetime.now() - timedelta(days=self.cleanup_days)
        filtered_data = []
        removed_count = 0
        
        for day in existing_by_date.values():
            try:
                date_str = day.get('date', '')
                if date_str:
                    # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD.MM.YYYY
                    day_date = datetime.strptime(date_str, '%d.%m.%Y')
                    if day_date >= cutoff_date:
                        filtered_data.append(day)
                    else:
                        removed_count += 1
                else:
                    filtered_data.append(day)
            except ValueError:
                # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ–Ω—å
                filtered_data.append(day)
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
        filtered_data.sort(key=lambda x: self._parse_date_key(x.get('date', '')))
        
        logger.info(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: –¥–æ–±–∞–≤–ª–µ–Ω–æ {added_count}, –æ–±–Ω–æ–≤–ª–µ–Ω–æ {updated_count}, "
                   f"—É–¥–∞–ª–µ–Ω–æ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö {removed_count}, –∏—Ç–æ–≥–æ {len(filtered_data)} –¥–Ω–µ–π")
        
        return filtered_data
    
    def _parse_date_key(self, date_str: str) -> datetime:
        """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∏."""
        try:
            return datetime.strptime(date_str, '%d.%m.%Y')
        except ValueError:
            return datetime.min
    
    def analyze_data_coverage(self, epg_data: List[Dict]) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–æ–∫—Ä—ã—Ç–∏–µ –¥–∞–Ω–Ω—ã—Ö."""
        if not epg_data:
            return {
                'start': None,
                'end': None,
                'days_count': 0,
                'programs_count': 0
            }
        
        dates = []
        total_programs = 0
        
        for day in epg_data:
            date_str = day.get('date', '')
            if date_str:
                try:
                    date_obj = datetime.strptime(date_str, '%d.%m.%Y')
                    dates.append(date_obj)
                    
                    # –°—á–∏—Ç–∞–µ–º –ø—Ä–æ–≥—Ä–∞–º–º—ã
                    programs = day.get('data', [])
                    total_programs += len(programs)
                except ValueError:
                    continue
        
        if not dates:
            return {
                'start': None,
                'end': None,
                'days_count': 0,
                'programs_count': 0
            }
        
        dates.sort()
        return {
            'start': dates[0].isoformat(),
            'end': dates[-1].isoformat(),
            'days_count': len(dates),
            'programs_count': total_programs
        }
    
    def save_metadata(self, epg_data: List[Dict], request_params: Dict[str, str]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ."""
        coverage = self.analyze_data_coverage(epg_data)
        
        metadata = {
            'last_update': datetime.now().isoformat(),
            'request_params': request_params,
            'date_coverage': coverage,
            'version': '1.0'
        }
        
        self.data_dir.mkdir(exist_ok=True)
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        logger.info(f"–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {coverage['days_count']} –¥–Ω–µ–π, "
                   f"{coverage['programs_count']} –ø—Ä–æ–≥—Ä–∞–º–º")


def smart_fetch_epg_simple(cfg: Config, session, data_dir: str = "data") -> List[Dict[str, Any]]:
    """
    –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è —É–º–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ EPG –¥–∞–Ω–Ω—ã—Ö.
    
    Args:
        cfg: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
        session: HTTP —Å–µ—Å—Å–∏—è
        data_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –¥–∞–Ω–Ω—ã—Ö
        
    Returns:
        –°–ø–∏—Å–æ–∫ EPG –¥–∞–Ω–Ω—ã—Ö
    """
    logger.info("üß† –ó–∞–ø—É—Å–∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π —É–º–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ EPG")
    
    manager = SimpleEPGManager(data_dir)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–æ –ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ
    should_update, reason = manager.should_update_epg()
    logger.info(f"üìã –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è: {reason}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    existing_data = []
    if manager.raw_epg_file.exists():
        try:
            with open(manager.raw_epg_file, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            existing_data = []
    
    if not should_update:
        logger.info("‚úÖ –î–∞–Ω–Ω—ã–µ –∞–∫—Ç—É–∞–ª—å–Ω—ã, –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è")
        return existing_data
    
    # –ü–æ–ª—É—á–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞
    request_params = manager.get_optimal_request_params()
    logger.info(f"üì° –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—Ä–æ—Å–∞: epg_from={request_params['epg_from']}, "
               f"epg_limit={request_params['epg_limit']}")
    
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    temp_params = cfg.iptv_params.copy()
    temp_params.update(request_params)
    
    temp_cfg = Config(
        iptv_base_url=cfg.iptv_base_url,
        iptv_params=temp_params,
        iptv_headers=cfg.iptv_headers,
        http_timeout=cfg.http_timeout,
        http_retries=cfg.http_retries,
        http_backoff=cfg.http_backoff,
        cache_enabled=cfg.cache_enabled,
        cache_path=cfg.cache_path,
        cache_expire=cfg.cache_expire,
        tmdb_api_key=cfg.tmdb_api_key,
        tmdb_base_url=cfg.tmdb_base_url,
        tmdb_image_base=cfg.tmdb_image_base,
        log_level=cfg.log_level,
        api_host=cfg.api_host,
        api_port=cfg.api_port,
        api_cache_ttl=cfg.api_cache_ttl,
        api_cors_origins=cfg.api_cors_origins,
        auto_run_pipeline=cfg.auto_run_pipeline
    )
    
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å
    try:
        new_data = _original_fetch_epg(temp_cfg, session)
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(new_data)} –¥–Ω–µ–π EPG –¥–∞–Ω–Ω—ã—Ö")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ EPG: {e}")
        return existing_data
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
    merged_data = manager.merge_epg_data(existing_data, new_data)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    manager.data_dir.mkdir(exist_ok=True)
    with open(manager.raw_epg_file, 'w', encoding='utf-8') as f:
        json.dump(merged_data, f, ensure_ascii=False, indent=2)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    manager.save_metadata(merged_data, request_params)
    
    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ {len(merged_data)} –¥–Ω–µ–π EPG –¥–∞–Ω–Ω—ã—Ö")
    return merged_data


# –ó–∞–º–µ–Ω—è–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
def fetch_epg_smart(cfg: Config, session) -> List[Dict[str, Any]]:
    """–û–±–µ—Ä—Ç–∫–∞ –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏."""
    return smart_fetch_epg_simple(cfg, session)
